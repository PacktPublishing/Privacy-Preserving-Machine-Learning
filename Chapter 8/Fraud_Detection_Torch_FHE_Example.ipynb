{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5aaa0fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>TRANSACTION_ID</th>\n",
       "      <th>TX_DATETIME</th>\n",
       "      <th>CUSTOMER_ID</th>\n",
       "      <th>TERMINAL_ID</th>\n",
       "      <th>TX_AMOUNT</th>\n",
       "      <th>TX_FRAUD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-02-01 00:43:37</td>\n",
       "      <td>901</td>\n",
       "      <td>8047</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-02-01 01:20:13</td>\n",
       "      <td>2611</td>\n",
       "      <td>7777</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-02-01 01:22:52</td>\n",
       "      <td>4212</td>\n",
       "      <td>3336</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-02-01 01:26:40</td>\n",
       "      <td>1293</td>\n",
       "      <td>7432</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2023-02-01 01:52:23</td>\n",
       "      <td>2499</td>\n",
       "      <td>1024</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  TRANSACTION_ID          TX_DATETIME  CUSTOMER_ID  TERMINAL_ID  \\\n",
       "0           0               0  2023-02-01 00:43:37          901         8047   \n",
       "1           1               1  2023-02-01 01:20:13         2611         7777   \n",
       "2           2               2  2023-02-01 01:22:52         4212         3336   \n",
       "3           3               3  2023-02-01 01:26:40         1293         7432   \n",
       "4           4               4  2023-02-01 01:52:23         2499         1024   \n",
       "\n",
       "   TX_AMOUNT  TX_FRAUD  \n",
       "0         82         1  \n",
       "1         15         0  \n",
       "2         53         0  \n",
       "3         59         0  \n",
       "4         25         0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "# /Users/arrao/Documents/Atchut/Book-PPML/Chapter6/simulated_transactions_csv3/transactions.csv \n",
    "\n",
    "url =\"/Users/arrao/Documents/Atchut/Book-PPML/Chapter6/fraud_transactions.csv\"\n",
    "#url = \"/Users/arrao/Documents/Atchut/Book-PPML/Chapter6/simulated_transactions_csv/2023-07-08.csv\"\n",
    "df_actual = pd.read_csv(url, sep=\",\")\n",
    "df_actual.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c55ba98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CUSTOMER_ID</th>\n",
       "      <th>TERMINAL_ID</th>\n",
       "      <th>TX_AMOUNT</th>\n",
       "      <th>TX_FRAUD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>901</td>\n",
       "      <td>8047</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2611</td>\n",
       "      <td>7777</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4212</td>\n",
       "      <td>3336</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1293</td>\n",
       "      <td>7432</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2499</td>\n",
       "      <td>1024</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>1541</td>\n",
       "      <td>3469</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>489</td>\n",
       "      <td>3854</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>4125</td>\n",
       "      <td>7519</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>3360</td>\n",
       "      <td>5215</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>951</td>\n",
       "      <td>9602</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CUSTOMER_ID  TERMINAL_ID  TX_AMOUNT  TX_FRAUD\n",
       "0              901         8047         82         1\n",
       "1             2611         7777         15         0\n",
       "2             4212         3336         53         0\n",
       "3             1293         7432         59         0\n",
       "4             2499         1024         25         0\n",
       "...            ...          ...        ...       ...\n",
       "49995         1541         3469         66         0\n",
       "49996          489         3854         89         1\n",
       "49997         4125         7519         12         0\n",
       "49998         3360         5215         86         1\n",
       "49999          951         9602         31         0\n",
       "\n",
       "[50000 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactions = df_actual[['CUSTOMER_ID','TERMINAL_ID','TX_AMOUNT','TX_FRAUD']]\n",
    "#df_transactions=df_transactions.head(10)\n",
    "df_transactions=df_transactions.head(50000)\n",
    "df_transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "098fe5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Fraud Transactions: 37870\n",
      "No of Non Fraud Transactions: 12130\n",
      "No Frauds 75.74 % of the dataset\n",
      "Frauds 24.26 % of the dataset\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "print(\"No of Fraud Transactions:\", df_transactions['TX_FRAUD'].value_counts()[0])\n",
    "print(\"No of Non Fraud Transactions:\", df_transactions['TX_FRAUD'].value_counts()[1])\n",
    "\n",
    "print('No Frauds', round(df_transactions['TX_FRAUD'].value_counts()[0]/len(df_transactions) * 100,2), '% of the dataset')\n",
    "print('Frauds', round(df_transactions['TX_FRAUD'].value_counts()[1]/len(df_transactions) * 100,2), '% of the dataset')\n",
    "\n",
    "\n",
    "\n",
    "X = df_transactions.drop('TX_FRAUD', axis=1)\n",
    "y = df_transactions['TX_FRAUD']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f7e2630",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "752dea0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor(X_train.values)\n",
    "x_test = torch.FloatTensor(X_test.values)\n",
    "y_train = torch.FloatTensor(y_train.values)\n",
    "y_test = torch.FloatTensor(y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95218fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# Data summary #############\n",
      "x_train has shape: torch.Size([35000, 3])\n",
      "y_train has shape: torch.Size([35000])\n",
      "x_test has shape: torch.Size([15000, 3])\n",
      "y_test has shape: torch.Size([15000])\n",
      "#######################################\n"
     ]
    }
   ],
   "source": [
    "print(\"############# Data summary #############\")\n",
    "print(f\"x_train has shape: {x_train.shape}\")\n",
    "print(f\"y_train has shape: {y_train.shape}\")\n",
    "print(f\"x_test has shape: {x_test.shape}\")\n",
    "print(f\"y_test has shape: {y_test.shape}\")\n",
    "print(\"#######################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a90a7da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected device is cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\" \n",
    "else:\n",
    "    DEVICE = \"cpu\"\n",
    "print(\"Selected device is\",DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5049b25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FraudDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, x, y):\n",
    "        'Initialization'\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        'Returns the total number of samples'\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample index\n",
    "        if self.y is not None:\n",
    "            return self.x[index].to(DEVICE), self.y[index].to(DEVICE)\n",
    "        else:\n",
    "            return self.x[index].to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93b58bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_params = {'batch_size': 64,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 0}\n",
    "test_loader_params = {'batch_size': 64,\n",
    "          'num_workers': 0}\n",
    "\n",
    "# Loaders\n",
    "\n",
    "training_set = FraudDataset(x_train, y_train)\n",
    "\n",
    "testing_set = FraudDataset(x_test, y_test)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(training_set, **train_loader_params)\n",
    "test_loader = torch.utils.data.DataLoader(testing_set, **test_loader_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34686936",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleFraudMLP(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.first_sec = torch.nn.Sequential(\n",
    "                           torch.nn.Linear(3, 450),\n",
    "                           torch.nn.ReLU(),\n",
    "        )\n",
    "        self.second_sec = torch.nn.Sequential(\n",
    "                           torch.nn.Linear(450, 450),\n",
    "                           torch.nn.ReLU(),\n",
    "                           torch.nn.Linear(450, 1),\n",
    "                           torch.nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.second_sec(self.first_sec(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6862fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_nn_model = SimpleFraudMLP().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae10277e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BCELoss()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn, optim\n",
    "#loss_func = nn.CrossEntropyLoss()   \n",
    "loss_func = torch.nn.BCELoss().to(DEVICE)\n",
    "loss_func\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7243291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    differentiable: False\n",
       "    foreach: None\n",
       "    lr: 0.07\n",
       "    maximize: False\n",
       "    momentum: 0\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#optimizer = optim.Adam(fraud_nn_model.parameters(), lr = 0.01)  \n",
    "optimizer = torch.optim.SGD(fraud_nn_model.parameters(), lr = 0.07)\n",
    "optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5538eeea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleFraudMLP(\n",
       "  (first_sec): Sequential(\n",
       "    (0): Linear(in_features=3, out_features=450, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (second_sec): Sequential(\n",
       "    (0): Linear(in_features=450, out_features=450, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=450, out_features=1, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_nn_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25f6a253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model,generator,loss_func):\n",
    "    model.eval()\n",
    "    batch_losses = []\n",
    "    for x_batch, y_batch in generator:\n",
    "        # Forward pass\n",
    "        y_pred = model(x_batch)\n",
    "        # Compute Loss\n",
    "        loss = loss_func(y_pred.squeeze(), y_batch)\n",
    "        batch_losses.append(loss.item())\n",
    "    mean_loss = np.mean(batch_losses)    \n",
    "    return mean_loss\n",
    "    \n",
    "#evaluate_model(fraud_nn_model,testing_loader,loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2be9ff56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SqueezeBackward0>)\n",
      "tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "0 24.191429138183594\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SqueezeBackward0>)\n",
      "tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "1 24.191429138183594\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SqueezeBackward0>)\n",
      "tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "2 24.191429138183594\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SqueezeBackward0>)\n",
      "tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "3 24.191429138183594\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SqueezeBackward0>)\n",
      "tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "4 24.191429138183594\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SqueezeBackward0>)\n",
      "tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "5 24.191429138183594\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SqueezeBackward0>)\n",
      "tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "6 24.191429138183594\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SqueezeBackward0>)\n",
      "tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "7 24.191429138183594\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SqueezeBackward0>)\n",
      "tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "8 24.191429138183594\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SqueezeBackward0>)\n",
      "tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "9 24.191429138183594\n"
     ]
    }
   ],
   "source": [
    "def train(fraud_nn_mode,num_epochs):\n",
    "    \n",
    "    fraud_nn_model.train()\n",
    "               \n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "         #for x_batch, y_batch in train_loader:\n",
    "                \n",
    "            output = fraud_nn_model(x_train)  \n",
    "            \n",
    "            print(output.squeeze())\n",
    "            \n",
    "            print(y_train)\n",
    "            \n",
    "            loss = loss_func(output.squeeze(), y_train)\n",
    "            \n",
    "            # clear gradients for this training step   \n",
    "            optimizer.zero_grad()           \n",
    "            \n",
    "            # backpropagation, compute gradients \n",
    "            loss.backward()    \n",
    "            # apply gradients             \n",
    "            optimizer.step()                \n",
    "            \n",
    "            print(epoch, loss.item())\n",
    "\n",
    "        \n",
    "    pass\n",
    "            \n",
    "train (fraud_nn_model, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07d1bc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on plain test_set: 0.244234099984169\n"
     ]
    }
   ],
   "source": [
    "def accuracy(model, x, y):\n",
    "    out = model(x)\n",
    "    correct = torch.abs(y - out) < 0.5\n",
    "    return correct.float().mean()\n",
    "\n",
    "plain_accuracy = accuracy(fraud_nn_model, x_test, y_test)\n",
    "print(f\"Accuracy on plain test_set: {plain_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5818c4f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac558e5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Using a target size (torch.Size([35000])) that is different to the input size (torch.Size([35000, 1])) is deprecated. Please ensure they have the same size.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 33\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss at epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[0;32m---> 33\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[30], line 27\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optim, criterion, x, y, epochs)\u001b[0m\n\u001b[1;32m     25\u001b[0m optim\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     26\u001b[0m out \u001b[38;5;241m=\u001b[39m model(x)\n\u001b[0;32m---> 27\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     29\u001b[0m optim\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/nn/modules/loss.py:619\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 619\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/nn/functional.py:3086\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3084\u001b[0m     reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[1;32m   3085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize():\n\u001b[0;32m-> 3086\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3087\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing a target size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) that is different to the input size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) is deprecated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3088\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure they have the same size.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(target\u001b[38;5;241m.\u001b[39msize(), \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m   3089\u001b[0m     )\n\u001b[1;32m   3091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3092\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n",
      "\u001b[0;31mValueError\u001b[0m: Using a target size (torch.Size([35000])) that is different to the input size (torch.Size([35000, 1])) is deprecated. Please ensure they have the same size."
     ]
    }
   ],
   "source": [
    "class LR(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lr = torch.nn.Sequential(\n",
    "                           torch.nn.Linear(3,1),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = torch.sigmoid(self.lr(x))\n",
    "        return out\n",
    "\n",
    "n_features = x_train.shape[1]\n",
    "model = LR()\n",
    "# use gradient descent with a learning_rate=1\n",
    "optim = torch.optim.SGD(model.parameters(), lr=1)\n",
    "# use Binary Cross Entropy Loss\n",
    "criterion = torch.nn.BCELoss()\n",
    "# define the number of epochs for both plain and encrypted training\n",
    "EPOCHS = 5\n",
    "\n",
    "def train(model, optim, criterion, x, y, epochs=EPOCHS):\n",
    "    for e in range(1, epochs + 1):\n",
    "        optim.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        print(f\"Loss at epoch {e}: {loss.data}\")\n",
    "    return model\n",
    "\n",
    "model = train(model, optim, criterion, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49bf3e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676823cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee7feee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2048f7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "415cbcc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss{} : 75.28534032679967\n",
      "Epoch 0: train loss: 75.28690740177356\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.8085714250837\n",
      "Epoch 1: train loss: 75.80920279047825\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857143205915\n",
      "Epoch 2: train loss: 75.80757051847971\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857142333984\n",
      "Epoch 3: train loss: 75.80961085847788\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857143380301\n",
      "Epoch 4: train loss: 75.81001894042522\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857143380301\n",
      "Epoch 5: train loss: 75.80716245048006\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857142857143\n",
      "Epoch 6: train loss: 75.80838665447898\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857143380301\n",
      "Epoch 7: train loss: 75.81001894042522\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857142857143\n",
      "Epoch 8: train loss: 75.80838665447898\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857142857143\n",
      "Epoch 9: train loss: 75.80838665447898\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.8085714303153\n",
      "Epoch 10: train loss: 75.80797858647934\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857142857143\n",
      "Epoch 11: train loss: 75.80838665447898\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857143205915\n",
      "Epoch 12: train loss: 75.81042700842487\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857143380301\n",
      "Epoch 13: train loss: 75.81001894042522\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.8085714303153\n",
      "Epoch 14: train loss: 75.80797858647934\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857142682757\n",
      "Epoch 15: train loss: 75.80879472247861\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857142857143\n",
      "Epoch 16: train loss: 75.80838665447898\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857143380301\n",
      "Epoch 17: train loss: 75.81001894042522\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857143380301\n",
      "Epoch 18: train loss: 75.81001894042522\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857142682757\n",
      "Epoch 19: train loss: 75.80879472247861\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857142682757\n",
      "Epoch 20: train loss: 75.80879472247861\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857142682757\n",
      "Epoch 21: train loss: 75.80879472247861\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857143380301\n",
      "Epoch 22: train loss: 75.81001894042522\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857143380301\n",
      "Epoch 23: train loss: 75.80716245048006\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.8085714303153\n",
      "Epoch 24: train loss: 75.8108350764245\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857143205915\n",
      "Epoch 25: train loss: 75.80757051847971\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857143380301\n",
      "Epoch 26: train loss: 75.81001894042522\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857143380301\n",
      "Epoch 27: train loss: 75.80716245048006\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857143380301\n",
      "Epoch 28: train loss: 75.81001894042522\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.8085714250837\n",
      "Epoch 29: train loss: 75.80920279047825\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.8085714303153\n",
      "Epoch 30: train loss: 75.8108350764245\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.8085714250837\n",
      "Epoch 31: train loss: 75.80920279047825\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857142857143\n",
      "Epoch 32: train loss: 75.81124314442413\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857142682757\n",
      "Epoch 33: train loss: 75.80879472247861\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857142857143\n",
      "Epoch 34: train loss: 75.80838665447898\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857143380301\n",
      "Epoch 35: train loss: 75.80716245048006\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.8085714250837\n",
      "Epoch 36: train loss: 75.80920279047825\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.8085714250837\n",
      "Epoch 37: train loss: 75.80920279047825\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.8085714250837\n",
      "Epoch 38: train loss: 75.80920279047825\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857142333984\n",
      "Epoch 39: train loss: 75.80961085847788\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857142857143\n",
      "Epoch 40: train loss: 75.80838665447898\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.8085714303153\n",
      "Epoch 41: train loss: 75.80797858647934\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857143205915\n",
      "Epoch 42: train loss: 75.80757051847971\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857142333984\n",
      "Epoch 43: train loss: 75.80961085847788\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857143205915\n",
      "Epoch 44: train loss: 75.80757051847971\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857142857143\n",
      "Epoch 45: train loss: 75.80838665447898\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.8085714250837\n",
      "Epoch 46: train loss: 75.8120592804234\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857142333984\n",
      "Epoch 47: train loss: 75.80961085847788\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857143205915\n",
      "Epoch 48: train loss: 75.80757051847971\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857143380301\n",
      "Epoch 49: train loss: 75.80716245048006\n",
      "test loss: 75.60062057819772\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "111.07959914207458"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "n_epochs = 50\n",
    "#Setting the model in training mode\n",
    "fraud_nn_model.train()\n",
    "\n",
    "#Training loop\n",
    "start_time=time.time()\n",
    "epochs_train_losses = []\n",
    "epochs_test_losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss=[]\n",
    "    train_loss1=0\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        \n",
    "        fraud_nn_model.train()\n",
    "        \n",
    "        # Performing the forward pass on the current batch\n",
    "        y_pred = fraud_nn_model(x_batch)\n",
    "        # Computing the loss given the current predictions\n",
    "        loss = loss_func(y_pred.squeeze(), y_batch)\n",
    "        # Computing the gradients over the backward pass\n",
    "        \n",
    "        # Removing previously computed gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        # Performing an optimization step from the current gradients\n",
    "        optimizer.step()\n",
    "        # Storing the current step's loss for display purposes\n",
    "        train_loss.append(loss.item())\n",
    "        \n",
    "        train_loss1 += loss.item()*x_batch.size(0)\n",
    "    avg_loss1 = train_loss1/len(train_loader.dataset)\n",
    "    print(\"Batch Loss{} :\", avg_loss1)\n",
    "    \n",
    "    #showing last training loss after each epoch\n",
    "    epochs_train_losses.append(np.mean(train_loss))\n",
    "    print('Epoch {}: train loss: {}'.format(epoch, np.mean(train_loss)))\n",
    "    \n",
    "    \n",
    "    #evaluating the model on the test set after each epoch    \n",
    "    val_loss = evaluate_model(fraud_nn_model,test_loader,loss_func)    \n",
    "    epochs_test_losses.append(val_loss)\n",
    "    print('test loss: {}'.format(val_loss))   \n",
    "    print(\"\")\n",
    "  \n",
    "    \n",
    "training_execution_time=time.time()-start_time\n",
    "training_execution_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb4aed9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b713bdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40382404",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b183fb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb48e35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfe09f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1194d35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
