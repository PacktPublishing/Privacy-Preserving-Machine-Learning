{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0ca03bd",
   "metadata": {},
   "source": [
    "# Fraud Detection Use case using Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5aaa0fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>TRANSACTION_ID</th>\n",
       "      <th>TX_DATETIME</th>\n",
       "      <th>CUSTOMER_ID</th>\n",
       "      <th>TERMINAL_ID</th>\n",
       "      <th>TX_AMOUNT</th>\n",
       "      <th>TX_FRAUD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-02-01 00:43:37</td>\n",
       "      <td>901</td>\n",
       "      <td>8047</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-02-01 01:20:13</td>\n",
       "      <td>2611</td>\n",
       "      <td>7777</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-02-01 01:22:52</td>\n",
       "      <td>4212</td>\n",
       "      <td>3336</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-02-01 01:26:40</td>\n",
       "      <td>1293</td>\n",
       "      <td>7432</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2023-02-01 01:52:23</td>\n",
       "      <td>2499</td>\n",
       "      <td>1024</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  TRANSACTION_ID          TX_DATETIME  CUSTOMER_ID  TERMINAL_ID  \\\n",
       "0           0               0  2023-02-01 00:43:37          901         8047   \n",
       "1           1               1  2023-02-01 01:20:13         2611         7777   \n",
       "2           2               2  2023-02-01 01:22:52         4212         3336   \n",
       "3           3               3  2023-02-01 01:26:40         1293         7432   \n",
       "4           4               4  2023-02-01 01:52:23         2499         1024   \n",
       "\n",
       "   TX_AMOUNT  TX_FRAUD  \n",
       "0         82         1  \n",
       "1         15         0  \n",
       "2         53         0  \n",
       "3         59         0  \n",
       "4         25         0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "url =\"fraud_transactions.csv\"\n",
    "\n",
    "df_actual = pd.read_csv(url, sep=\",\")\n",
    "df_actual.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c55ba98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CUSTOMER_ID</th>\n",
       "      <th>TERMINAL_ID</th>\n",
       "      <th>TX_AMOUNT</th>\n",
       "      <th>TX_FRAUD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>901</td>\n",
       "      <td>8047</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2611</td>\n",
       "      <td>7777</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4212</td>\n",
       "      <td>3336</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1293</td>\n",
       "      <td>7432</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2499</td>\n",
       "      <td>1024</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>1541</td>\n",
       "      <td>3469</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>489</td>\n",
       "      <td>3854</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>4125</td>\n",
       "      <td>7519</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>3360</td>\n",
       "      <td>5215</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>951</td>\n",
       "      <td>9602</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CUSTOMER_ID  TERMINAL_ID  TX_AMOUNT  TX_FRAUD\n",
       "0              901         8047         82         1\n",
       "1             2611         7777         15         0\n",
       "2             4212         3336         53         0\n",
       "3             1293         7432         59         0\n",
       "4             2499         1024         25         0\n",
       "...            ...          ...        ...       ...\n",
       "49995         1541         3469         66         0\n",
       "49996          489         3854         89         1\n",
       "49997         4125         7519         12         0\n",
       "49998         3360         5215         86         1\n",
       "49999          951         9602         31         0\n",
       "\n",
       "[50000 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactions = df_actual[['CUSTOMER_ID','TERMINAL_ID','TX_AMOUNT','TX_FRAUD']]\n",
    "#df_transactions=df_transactions.head(10)\n",
    "df_transactions=df_transactions.head(50000)\n",
    "df_transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "098fe5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Fraud Transactions: 37870\n",
      "No of Non Fraud Transactions: 12130\n",
      "No Frauds 75.74 % of the dataset\n",
      "Frauds 24.26 % of the dataset\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "print(\"No of Fraud Transactions:\", df_transactions['TX_FRAUD'].value_counts()[0])\n",
    "print(\"No of Non Fraud Transactions:\", df_transactions['TX_FRAUD'].value_counts()[1])\n",
    "\n",
    "print('No Frauds', round(df_transactions['TX_FRAUD'].value_counts()[0]/len(df_transactions) * 100,2), '% of the dataset')\n",
    "print('Frauds', round(df_transactions['TX_FRAUD'].value_counts()[1]/len(df_transactions) * 100,2), '% of the dataset')\n",
    "\n",
    "\n",
    "\n",
    "X = df_transactions.drop('TX_FRAUD', axis=1)\n",
    "y = df_transactions['TX_FRAUD']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5f7e2630",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "752dea0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor(X_train.values)\n",
    "x_test = torch.FloatTensor(X_test.values)\n",
    "y_train = torch.FloatTensor(y_train.values)\n",
    "y_test = torch.FloatTensor(y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a90a7da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected device is cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\" \n",
    "else:\n",
    "    DEVICE = \"cpu\"\n",
    "print(\"Selected device is\",DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5049b25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FraudDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, x, y):\n",
    "        'Initialization'\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        'Returns the total number of samples'\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample index\n",
    "        if self.y is not None:\n",
    "            return self.x[index].to(DEVICE), self.y[index].to(DEVICE)\n",
    "        else:\n",
    "            return self.x[index].to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "93b58bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_params = {'batch_size': 64,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 0}\n",
    "test_loader_params = {'batch_size': 64,\n",
    "          'num_workers': 0}\n",
    "\n",
    "# Loaders\n",
    "\n",
    "training_set = FraudDataset(x_train, y_train)\n",
    "\n",
    "testing_set = FraudDataset(x_test, y_test)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(training_set, **train_loader_params)\n",
    "test_loader = torch.utils.data.DataLoader(testing_set, **test_loader_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "34686936",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleFraudMLP(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.first_sec = torch.nn.Sequential(\n",
    "                           torch.nn.Linear(3, 450),\n",
    "                           torch.nn.ReLU(),\n",
    "        )\n",
    "        self.second_sec = torch.nn.Sequential(\n",
    "                           torch.nn.Linear(450, 450),\n",
    "                           torch.nn.ReLU(),\n",
    "                           torch.nn.Linear(450, 1),\n",
    "                           torch.nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.second_sec(self.first_sec(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a6862fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_nn_model = SimpleFraudMLP().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ae10277e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BCELoss()"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn, optim\n",
    "#loss_func = nn.CrossEntropyLoss()   \n",
    "loss_func = torch.nn.BCELoss().to(DEVICE)\n",
    "loss_func\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f7243291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    differentiable: False\n",
       "    foreach: None\n",
       "    lr: 0.07\n",
       "    maximize: False\n",
       "    momentum: 0\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#optimizer = optim.Adam(fraud_nn_model.parameters(), lr = 0.01)  \n",
    "optimizer = torch.optim.SGD(fraud_nn_model.parameters(), lr = 0.07)\n",
    "optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5538eeea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleFraudMLP(\n",
       "  (first_sec): Sequential(\n",
       "    (0): Linear(in_features=3, out_features=450, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (second_sec): Sequential(\n",
       "    (0): Linear(in_features=450, out_features=450, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=450, out_features=1, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_nn_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "25f6a253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model,generator,loss_func):\n",
    "    model.eval()\n",
    "    batch_losses = []\n",
    "    for x_batch, y_batch in generator:\n",
    "        # Forward pass\n",
    "        y_pred = model(x_batch)\n",
    "        # Compute Loss\n",
    "        loss = loss_func(y_pred.squeeze(), y_batch)\n",
    "        batch_losses.append(loss.item())\n",
    "    mean_loss = np.mean(batch_losses)    \n",
    "    return mean_loss\n",
    "    \n",
    "#evaluate_model(fraud_nn_model,testing_loader,loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2be9ff56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SqueezeBackward0>)\n",
      "tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "0 24.191429138183594\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SqueezeBackward0>)\n",
      "tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "1 24.191429138183594\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SqueezeBackward0>)\n",
      "tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "2 24.191429138183594\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SqueezeBackward0>)\n",
      "tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "3 24.191429138183594\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SqueezeBackward0>)\n",
      "tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "4 24.191429138183594\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SqueezeBackward0>)\n",
      "tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "5 24.191429138183594\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SqueezeBackward0>)\n",
      "tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "6 24.191429138183594\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SqueezeBackward0>)\n",
      "tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "7 24.191429138183594\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SqueezeBackward0>)\n",
      "tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "8 24.191429138183594\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SqueezeBackward0>)\n",
      "tensor([1., 1., 1.,  ..., 0., 0., 0.])\n",
      "9 24.191429138183594\n"
     ]
    }
   ],
   "source": [
    "def train(fraud_nn_mode,num_epochs):\n",
    "    \n",
    "    fraud_nn_model.train()\n",
    "               \n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "         #for x_batch, y_batch in train_loader:\n",
    "                \n",
    "            output = fraud_nn_model(x_train)  \n",
    "            \n",
    "            print(output.squeeze())\n",
    "            \n",
    "            print(y_train)\n",
    "            \n",
    "            loss = loss_func(output.squeeze(), y_train)\n",
    "            \n",
    "            # clear gradients for this training step   \n",
    "            optimizer.zero_grad()           \n",
    "            \n",
    "            # backpropagation, compute gradients \n",
    "            loss.backward()    \n",
    "            # apply gradients             \n",
    "            optimizer.step()                \n",
    "            \n",
    "            print(epoch, loss.item())\n",
    "\n",
    "        \n",
    "    pass\n",
    "            \n",
    "train (fraud_nn_model, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "415cbcc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss{} : 75.28534032679967\n",
      "Epoch 0: train loss: 75.28690740177356\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.8085714250837\n",
      "Epoch 1: train loss: 75.80920279047825\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857143205915\n",
      "Epoch 2: train loss: 75.80757051847971\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857142333984\n",
      "Epoch 3: train loss: 75.80961085847788\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857143380301\n",
      "Epoch 4: train loss: 75.81001894042522\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857143380301\n",
      "Epoch 5: train loss: 75.80716245048006\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857142857143\n",
      "Epoch 6: train loss: 75.80838665447898\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857143380301\n",
      "Epoch 7: train loss: 75.81001894042522\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857142857143\n",
      "Epoch 8: train loss: 75.80838665447898\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857142857143\n",
      "Epoch 9: train loss: 75.80838665447898\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.8085714303153\n",
      "Epoch 10: train loss: 75.80797858647934\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857142857143\n",
      "Epoch 11: train loss: 75.80838665447898\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857143205915\n",
      "Epoch 12: train loss: 75.81042700842487\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857143380301\n",
      "Epoch 13: train loss: 75.81001894042522\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.8085714303153\n",
      "Epoch 14: train loss: 75.80797858647934\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857142682757\n",
      "Epoch 15: train loss: 75.80879472247861\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857142857143\n",
      "Epoch 16: train loss: 75.80838665447898\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857143380301\n",
      "Epoch 17: train loss: 75.81001894042522\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857143380301\n",
      "Epoch 18: train loss: 75.81001894042522\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857142682757\n",
      "Epoch 19: train loss: 75.80879472247861\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857142682757\n",
      "Epoch 20: train loss: 75.80879472247861\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857142682757\n",
      "Epoch 21: train loss: 75.80879472247861\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857143380301\n",
      "Epoch 22: train loss: 75.81001894042522\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857143380301\n",
      "Epoch 23: train loss: 75.80716245048006\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.8085714303153\n",
      "Epoch 24: train loss: 75.8108350764245\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857143205915\n",
      "Epoch 25: train loss: 75.80757051847971\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857143380301\n",
      "Epoch 26: train loss: 75.81001894042522\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857143380301\n",
      "Epoch 27: train loss: 75.80716245048006\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857143380301\n",
      "Epoch 28: train loss: 75.81001894042522\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.8085714250837\n",
      "Epoch 29: train loss: 75.80920279047825\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.8085714303153\n",
      "Epoch 30: train loss: 75.8108350764245\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.8085714250837\n",
      "Epoch 31: train loss: 75.80920279047825\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857142857143\n",
      "Epoch 32: train loss: 75.81124314442413\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857142682757\n",
      "Epoch 33: train loss: 75.80879472247861\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857142857143\n",
      "Epoch 34: train loss: 75.80838665447898\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857143380301\n",
      "Epoch 35: train loss: 75.80716245048006\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.8085714250837\n",
      "Epoch 36: train loss: 75.80920279047825\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.8085714250837\n",
      "Epoch 37: train loss: 75.80920279047825\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.8085714250837\n",
      "Epoch 38: train loss: 75.80920279047825\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857142333984\n",
      "Epoch 39: train loss: 75.80961085847788\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857142857143\n",
      "Epoch 40: train loss: 75.80838665447898\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.8085714303153\n",
      "Epoch 41: train loss: 75.80797858647934\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857143205915\n",
      "Epoch 42: train loss: 75.80757051847971\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857142333984\n",
      "Epoch 43: train loss: 75.80961085847788\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857143205915\n",
      "Epoch 44: train loss: 75.80757051847971\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857142857143\n",
      "Epoch 45: train loss: 75.80838665447898\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.8085714250837\n",
      "Epoch 46: train loss: 75.8120592804234\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857142333984\n",
      "Epoch 47: train loss: 75.80961085847788\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857143205915\n",
      "Epoch 48: train loss: 75.80757051847971\n",
      "test loss: 75.60062057819772\n",
      "\n",
      "Batch Loss{} : 75.80857143380301\n",
      "Epoch 49: train loss: 75.80716245048006\n",
      "test loss: 75.60062057819772\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "111.07959914207458"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "n_epochs = 50\n",
    "#Setting the model in training mode\n",
    "fraud_nn_model.train()\n",
    "\n",
    "#Training loop\n",
    "start_time=time.time()\n",
    "epochs_train_losses = []\n",
    "epochs_test_losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss=[]\n",
    "    train_loss1=0\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        \n",
    "        fraud_nn_model.train()\n",
    "        \n",
    "        # Performing the forward pass on the current batch\n",
    "        y_pred = fraud_nn_model(x_batch)\n",
    "        # Computing the loss given the current predictions\n",
    "        loss = loss_func(y_pred.squeeze(), y_batch)\n",
    "        # Computing the gradients over the backward pass\n",
    "        \n",
    "        # Removing previously computed gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        # Performing an optimization step from the current gradients\n",
    "        optimizer.step()\n",
    "        # Storing the current step's loss for display purposes\n",
    "        train_loss.append(loss.item())\n",
    "        \n",
    "        train_loss1 += loss.item()*x_batch.size(0)\n",
    "    avg_loss1 = train_loss1/len(train_loader.dataset)\n",
    "    print(\"Batch Loss{} :\", avg_loss1)\n",
    "    \n",
    "    #showing last training loss after each epoch\n",
    "    epochs_train_losses.append(np.mean(train_loss))\n",
    "    print('Epoch {}: train loss: {}'.format(epoch, np.mean(train_loss)))\n",
    "    \n",
    "    \n",
    "    #evaluating the model on the test set after each epoch    \n",
    "    val_loss = evaluate_model(fraud_nn_model,test_loader,loss_func)    \n",
    "    epochs_test_losses.append(val_loss)\n",
    "    print('test loss: {}'.format(val_loss))   \n",
    "    print(\"\")\n",
    "  \n",
    "    \n",
    "training_execution_time=time.time()-start_time\n",
    "training_execution_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1194d35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
