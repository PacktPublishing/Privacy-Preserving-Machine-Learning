{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-20T05:27:57.868429Z",
     "iopub.status.busy": "2023-09-20T05:27:57.867973Z",
     "iopub.status.idle": "2023-09-20T05:29:30.065678Z",
     "shell.execute_reply": "2023-09-20T05:29:30.064238Z",
     "shell.execute_reply.started": "2023-09-20T05:27:57.868396Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textattack\n",
      "  Downloading textattack-0.3.9-py3-none-any.whl (436 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.8/436.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting bert-score>=0.3.5 (from textattack)\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting editdistance (from textattack)\n",
      "  Downloading editdistance-0.6.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (282 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m282.6/282.6 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting flair (from textattack)\n",
      "  Downloading flair-0.12.2-py3-none-any.whl (373 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m373.1/373.1 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from textattack) (3.12.2)\n",
      "Collecting language-tool-python (from textattack)\n",
      "  Downloading language_tool_python-2.7.1-py3-none-any.whl (34 kB)\n",
      "Collecting lemminflect (from textattack)\n",
      "  Downloading lemminflect-0.2.3-py3-none-any.whl (769 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m769.7/769.7 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting lru-dict (from textattack)\n",
      "  Downloading lru_dict-1.2.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
      "Collecting datasets>=2.4.0 (from textattack)\n",
      "  Downloading datasets-2.14.5-py3-none-any.whl (519 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from textattack) (3.2.4)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.10/site-packages (from textattack) (1.23.5)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from textattack) (2.0.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from textattack) (1.11.2)\n",
      "Requirement already satisfied: torch!=1.8,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from textattack) (2.0.0+cpu)\n",
      "Requirement already satisfied: transformers>=4.30.0 in /opt/conda/lib/python3.10/site-packages (from textattack) (4.33.0)\n",
      "Collecting terminaltables (from textattack)\n",
      "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from textattack) (4.66.1)\n",
      "Collecting word2number (from textattack)\n",
      "  Downloading word2number-1.1.zip (9.7 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting num2words (from textattack)\n",
      "  Downloading num2words-0.5.12-py3-none-any.whl (125 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: more-itertools in /opt/conda/lib/python3.10/site-packages (from textattack) (9.1.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from textattack) (1.7.1)\n",
      "Collecting pinyin>=0.4.0 (from textattack)\n",
      "  Downloading pinyin-0.4.0.tar.gz (3.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: jieba in /opt/conda/lib/python3.10/site-packages (from textattack) (0.42.1)\n",
      "Collecting OpenHowNet (from textattack)\n",
      "  Downloading OpenHowNet-2.0-py3-none-any.whl (18 kB)\n",
      "Collecting pycld2 (from textattack)\n",
      "  Downloading pycld2-0.41.tar.gz (41.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.4/41.4 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting click<8.1.0 (from textattack)\n",
      "  Downloading click-8.0.4-py3-none-any.whl (97 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.5/97.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from bert-score>=0.3.5->textattack) (2.31.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from bert-score>=0.3.5->textattack) (3.7.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from bert-score>=0.3.5->textattack) (21.3)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.4.0->textattack) (9.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.4.0->textattack) (0.3.7)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets>=2.4.0->textattack) (3.3.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets>=2.4.0->textattack) (0.70.15)\n",
      "Collecting fsspec[http]<2023.9.0,>=2023.1.0 (from datasets>=2.4.0->textattack)\n",
      "  Downloading fsspec-2023.6.0-py3-none-any.whl (163 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.4.0->textattack) (3.8.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.4.0->textattack) (0.16.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.4.0->textattack) (6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->textattack) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->textattack) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->textattack) (2023.3)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch!=1.8,>=1.7.0->textattack) (4.6.3)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch!=1.8,>=1.7.0->textattack) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch!=1.8,>=1.7.0->textattack) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch!=1.8,>=1.7.0->textattack) (3.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.30.0->textattack) (2023.6.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.30.0->textattack) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.30.0->textattack) (0.3.3)\n",
      "Requirement already satisfied: gensim>=3.8.0 in /opt/conda/lib/python3.10/site-packages (from flair->textattack) (4.3.2)\n",
      "Collecting segtok>=1.5.7 (from flair->textattack)\n",
      "  Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
      "Collecting mpld3==0.3 (from flair->textattack)\n",
      "  Downloading mpld3-0.3.tar.gz (788 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m788.5/788.5 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.10/site-packages (from flair->textattack) (1.2.2)\n",
      "Collecting sqlitedict>=1.6.0 (from flair->textattack)\n",
      "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: deprecated>=1.2.4 in /opt/conda/lib/python3.10/site-packages (from flair->textattack) (1.2.14)\n",
      "Requirement already satisfied: hyperopt>=0.2.7 in /opt/conda/lib/python3.10/site-packages (from flair->textattack) (0.2.7)\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.10/site-packages (from flair->textattack) (1.26.100)\n",
      "Collecting bpemb>=0.3.2 (from flair->textattack)\n",
      "  Downloading bpemb-0.3.4-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from flair->textattack) (0.9.0)\n",
      "Collecting langdetect (from flair->textattack)\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from flair->textattack) (4.9.3)\n",
      "Collecting ftfy (from flair->textattack)\n",
      "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: janome in /opt/conda/lib/python3.10/site-packages (from flair->textattack) (0.5.0)\n",
      "Collecting gdown==4.4.0 (from flair->textattack)\n",
      "  Downloading gdown-4.4.0.tar.gz (14 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting conllu>=4.0 (from flair->textattack)\n",
      "  Downloading conllu-4.5.3-py2.py3-none-any.whl (16 kB)\n",
      "Collecting wikipedia-api (from flair->textattack)\n",
      "  Downloading Wikipedia_API-0.6.0-py3-none-any.whl (14 kB)\n",
      "Collecting pptree (from flair->textattack)\n",
      "  Downloading pptree-3.1.tar.gz (3.0 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pytorch-revgrad (from flair->textattack)\n",
      "  Downloading pytorch_revgrad-0.2.0-py3-none-any.whl (4.6 kB)\n",
      "Collecting transformer-smaller-training-vocab>=0.2.1 (from flair->textattack)\n",
      "  Downloading transformer_smaller_training_vocab-0.3.2-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from gdown==4.4.0->flair->textattack) (1.16.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown==4.4.0->flair->textattack) (4.12.2)\n",
      "Requirement already satisfied: docopt>=0.6.2 in /opt/conda/lib/python3.10/site-packages (from num2words->textattack) (0.6.2)\n",
      "Collecting anytree (from OpenHowNet->textattack)\n",
      "  Downloading anytree-2.9.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from OpenHowNet->textattack) (68.0.0)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from bpemb>=0.3.2->flair->textattack) (0.1.99)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.10/site-packages (from deprecated>=1.2.4->flair->textattack) (1.14.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.4.0->textattack) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.4.0->textattack) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.4.0->textattack) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.4.0->textattack) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.4.0->textattack) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.4.0->textattack) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.4.0->textattack) (1.3.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.10/site-packages (from gensim>=3.8.0->flair->textattack) (6.3.0)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.10/site-packages (from hyperopt>=0.2.7->flair->textattack) (0.18.3)\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.10/site-packages (from hyperopt>=0.2.7->flair->textattack) (2.2.1)\n",
      "Requirement already satisfied: py4j in /opt/conda/lib/python3.10/site-packages (from hyperopt>=0.2.7->flair->textattack) (0.10.9.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score>=0.3.5->textattack) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score>=0.3.5->textattack) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score>=0.3.5->textattack) (4.40.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score>=0.3.5->textattack) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score>=0.3.5->textattack) (9.5.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score>=0.3.5->textattack) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->bert-score>=0.3.5->textattack) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->bert-score>=0.3.5->textattack) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->bert-score>=0.3.5->textattack) (2023.7.22)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->flair->textattack) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->flair->textattack) (3.1.0)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from transformers>=4.30.0->textattack) (3.20.3)\n",
      "Collecting botocore<1.30.0,>=1.29.100 (from boto3->flair->textattack)\n",
      "  Downloading botocore-1.29.165-py3-none-any.whl (11.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3->flair->textattack) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from boto3->flair->textattack) (0.6.2)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /opt/conda/lib/python3.10/site-packages (from ftfy->flair->textattack) (0.2.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch!=1.8,>=1.7.0->textattack) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch!=1.8,>=1.7.0->textattack) (1.3.0)\n",
      "Requirement already satisfied: accelerate>=0.20.3 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.30.0->textattack) (0.22.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown==4.4.0->flair->textattack) (2.3.2.post1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.20.3->transformers>=4.30.0->textattack) (5.9.3)\n",
      "Building wheels for collected packages: pinyin, gdown, mpld3, pycld2, word2number, sqlitedict, langdetect, pptree\n",
      "  Building wheel for pinyin (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pinyin: filename=pinyin-0.4.0-py3-none-any.whl size=3630476 sha256=1a827a57a317c71bfc8f7eacdbc4390d80f2519b42852629659fcd055dfc081c\n",
      "  Stored in directory: /root/.cache/pip/wheels/33/38/af/616fc6f154aa5bae65a1da12b22d79943434269f0468ff9b3f\n",
      "  Building wheel for gdown (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gdown: filename=gdown-4.4.0-py3-none-any.whl size=14758 sha256=f15234525b8dfa7c403f636d0e7fe68cab09d419cdcfe9cdb15a0fe14a80f132\n",
      "  Stored in directory: /root/.cache/pip/wheels/03/0b/3f/6ddf67a417a5b400b213b0bb772a50276c199a386b12c06bfc\n",
      "  Building wheel for mpld3 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for mpld3: filename=mpld3-0.3-py3-none-any.whl size=116685 sha256=a8e94ab152a12a185a67a3f1d5ff27b2892f475d886062d668eafa7163cbb822\n",
      "  Stored in directory: /root/.cache/pip/wheels/9c/92/f7/45d9aac5dcfb1c2a1761a272365599cc7ba1050ce211a3fd9a\n",
      "  Building wheel for pycld2 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pycld2: filename=pycld2-0.41-cp310-cp310-linux_x86_64.whl size=4797790 sha256=357c5ff11d2c004a2e2ea7d1d7cc30175559b1bea03c4d3b79654548a5420c62\n",
      "  Stored in directory: /root/.cache/pip/wheels/be/81/31/240c89c845e008a93d98542325270007de595bfd356eb0b06c\n",
      "  Building wheel for word2number (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5569 sha256=0b840d574c7d238db754503e7ed1900b914f36bce03880cd9afa9dbdddd64472\n",
      "  Stored in directory: /root/.cache/pip/wheels/84/ff/26/d3cfbd971e96c5aa3737ecfced81628830d7359b55fbb8ca3b\n",
      "  Building wheel for sqlitedict (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16863 sha256=472bd37e73a1b7192401eff71844338b4965beb8d6c159ccca68160c908bd7f4\n",
      "  Stored in directory: /root/.cache/pip/wheels/79/d6/e7/304e0e6cb2221022c26d8161f7c23cd4f259a9e41e8bbcfabd\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993224 sha256=a1f12c4883203577ccc68376dc9e3848c4dd1d7d916b8bfbd323f4d7294391c0\n",
      "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
      "  Building wheel for pptree (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pptree: filename=pptree-3.1-py3-none-any.whl size=4609 sha256=9a7b5ba1cc72988ab69c4dcf55e1257398ad3b06ca9c0d0d4407a04d7ffb7e79\n",
      "  Stored in directory: /root/.cache/pip/wheels/9f/b6/0e/6f26eb9e6eb53ff2107a7888d72b5a6a597593956113037828\n",
      "Successfully built pinyin gdown mpld3 pycld2 word2number sqlitedict langdetect pptree\n",
      "Installing collected packages: word2number, sqlitedict, pycld2, pptree, pinyin, mpld3, lru-dict, terminaltables, segtok, num2words, lemminflect, langdetect, ftfy, fsspec, editdistance, conllu, click, anytree, wikipedia-api, OpenHowNet, language-tool-python, botocore, pytorch-revgrad, gdown, bpemb, datasets, bert-score, transformer-smaller-training-vocab, flair, textattack\n",
      "  Attempting uninstall: mpld3\n",
      "    Found existing installation: mpld3 0.5.9\n",
      "    Uninstalling mpld3-0.5.9:\n",
      "      Successfully uninstalled mpld3-0.5.9\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.9.0\n",
      "    Uninstalling fsspec-2023.9.0:\n",
      "      Successfully uninstalled fsspec-2023.9.0\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 8.1.7\n",
      "    Uninstalling click-8.1.7:\n",
      "      Successfully uninstalled click-8.1.7\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.31.17\n",
      "    Uninstalling botocore-1.31.17:\n",
      "      Successfully uninstalled botocore-1.31.17\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.1.0\n",
      "    Uninstalling datasets-2.1.0:\n",
      "      Successfully uninstalled datasets-2.1.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiobotocore 2.5.4 requires botocore<1.31.18,>=1.31.17, but you have botocore 1.29.165 which is incompatible.\n",
      "fitter 1.6.0 requires click<9.0.0,>=8.1.6, but you have click 8.0.4 which is incompatible.\n",
      "flask 2.3.3 requires click>=8.1.3, but you have click 8.0.4 which is incompatible.\n",
      "kfp 2.0.1 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\n",
      "momepy 0.6.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\n",
      "s3fs 2023.9.0 requires fsspec==2023.9.0, but you have fsspec 2023.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed OpenHowNet-2.0 anytree-2.9.0 bert-score-0.3.13 botocore-1.29.165 bpemb-0.3.4 click-8.0.4 conllu-4.5.3 datasets-2.14.5 editdistance-0.6.2 flair-0.12.2 fsspec-2023.6.0 ftfy-6.1.1 gdown-4.4.0 langdetect-1.0.9 language-tool-python-2.7.1 lemminflect-0.2.3 lru-dict-1.2.0 mpld3-0.3 num2words-0.5.12 pinyin-0.4.0 pptree-3.1 pycld2-0.41 pytorch-revgrad-0.2.0 segtok-1.5.11 sqlitedict-2.1.0 terminaltables-3.1.10 textattack-0.3.9 transformer-smaller-training-vocab-0.3.2 wikipedia-api-0.6.0 word2number-1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install textattack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-20T06:05:16.174519Z",
     "iopub.status.busy": "2023-09-20T06:05:16.173790Z",
     "iopub.status.idle": "2023-09-20T06:06:46.197309Z",
     "shell.execute_reply": "2023-09-20T06:06:46.196181Z",
     "shell.execute_reply.started": "2023-09-20T06:05:16.174479Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Unknown if model of class <class '__main__.Model'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack(\n",
      "  (search_method): GreedyWordSwapWIR(\n",
      "    (wir_method):  delete\n",
      "  )\n",
      "  (goal_function):  UntargetedClassification\n",
      "  (transformation):  WordSwapEmbedding(\n",
      "    (max_candidates):  50\n",
      "    (embedding):  WordEmbedding\n",
      "  )\n",
      "  (constraints): \n",
      "    (0): WordEmbeddingDistance(\n",
      "        (embedding):  WordEmbedding\n",
      "        (min_cos_sim):  0.5\n",
      "        (cased):  False\n",
      "        (include_unknown_words):  True\n",
      "        (compare_against_original):  True\n",
      "      )\n",
      "    (1): PartOfSpeech(\n",
      "        (tagger_type):  nltk\n",
      "        (tagset):  universal\n",
      "        (allow_verb_noun_swap):  True\n",
      "        (compare_against_original):  True\n",
      "      )\n",
      "    (2): UniversalSentenceEncoder(\n",
      "        (metric):  angular\n",
      "        (threshold):  0.840845057\n",
      "        (window_size):  15\n",
      "        (skip_text_shorter_than_window):  True\n",
      "        (compare_against_original):  False\n",
      "      )\n",
      "    (3): RepeatModification\n",
      "    (4): StopwordModification\n",
      "    (5): InputColumnModification(\n",
      "        (matching_column_labels):  ['premise', 'hypothesis']\n",
      "        (columns_to_ignore):  {'premise'}\n",
      "      )\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:48<07:13, 48.12s/it]\u001b[A\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 1 / 0 / 1:  10%|█         | 1/10 [00:48<07:13, 48.12s/it]\u001b[A\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 1 / 0 / 1:  20%|██        | 2/10 [00:48<03:12, 24.11s/it]\u001b[A\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 1 / 1 / 2:  20%|██        | 2/10 [00:48<03:12, 24.12s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 1 ---------------------------------------------\n",
      "[[0 (56%)]] --> [[[FAILED]]]\n",
      "\n",
      "Explosions and CGI can't make up for the lackluster story in Transformers: The Last Knight. Disappointing.\n",
      "\n",
      "\n",
      "--------------------------------------------- Result 2 ---------------------------------------------\n",
      "[[0 (55%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "Forrest Gump is a heartwarming journey through history. Tom Hanks delivers an unforgettable performance.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 1 / 1 / 2:  30%|███       | 3/10 [00:48<01:52, 16.11s/it]\u001b[A\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 1 / 2 / 3:  30%|███       | 3/10 [00:48<01:52, 16.11s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 3 ---------------------------------------------\n",
      "[[0 (57%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "The Room is so bad that it's almost good. The unintentional humor makes it a cult classic.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 1 / 2 / 3:  40%|████      | 4/10 [01:01<01:32, 15.47s/it]\u001b[A\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 2 / 2 / 4:  40%|████      | 4/10 [01:01<01:32, 15.47s/it]\u001b[A\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 2 / 2 / 4:  50%|█████     | 5/10 [01:01<01:01, 12.40s/it]\u001b[A\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 2 / 3 / 5:  50%|█████     | 5/10 [01:01<01:01, 12.40s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 4 ---------------------------------------------\n",
      "[[0 (58%)]] --> [[[FAILED]]]\n",
      "\n",
      "Twilight is a guilty pleasure for some, but the acting and dialogue are cringe-worthy. Not a cinematic masterpiece.\n",
      "\n",
      "\n",
      "--------------------------------------------- Result 5 ---------------------------------------------\n",
      "[[0 (54%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "The Godfather is a cinematic gem. The storytelling and performances are top-notch. A true classic in every sense.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 2 / 3 / 5:  60%|██████    | 6/10 [01:27<00:58, 14.51s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 6 ---------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Succeeded / Failed / Skipped / Total] 1 / 2 / 3 / 6:  60%|██████    | 6/10 [01:27<00:58, 14.60s/it]\u001b[A\n",
      "[Succeeded / Failed / Skipped / Total] 1 / 2 / 3 / 6:  70%|███████   | 7/10 [01:27<00:37, 12.54s/it]\u001b[A\n",
      "[Succeeded / Failed / Skipped / Total] 1 / 2 / 4 / 7:  70%|███████   | 7/10 [01:27<00:37, 12.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 (59%)]] --> [[1 (51%)]]\n",
      "\n",
      "[[The]] Emoji Movie is a [[complete]] [[disappointment]]. The [[plot]] is weak, and it [[feels]] like one [[big]] [[advertisement]]. [[A]] [[waste]] of time.\n",
      "\n",
      "[[Both]] Emoji Movie is a [[fulfills]] [[dissatisfaction]]. The [[plots]] is weak, and it [[reckon]] like one [[largest]] [[commercials]]. [[para]] [[vandalize]] of time.\n",
      "\n",
      "\n",
      "--------------------------------------------- Result 7 ---------------------------------------------\n",
      "[[0 (56%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "Avatar is visually breathtaking, but the story is somewhat predictable. Still, it's a cinematic experience.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Succeeded / Failed / Skipped / Total] 1 / 2 / 4 / 7:  80%|████████  | 8/10 [01:27<00:21, 10.99s/it]\u001b[A\n",
      "[Succeeded / Failed / Skipped / Total] 1 / 2 / 5 / 8:  80%|████████  | 8/10 [01:27<00:21, 10.99s/it]\u001b[A\n",
      "[Succeeded / Failed / Skipped / Total] 1 / 2 / 5 / 8:  90%|█████████ | 9/10 [01:28<00:09,  9.78s/it]\u001b[A\n",
      "[Succeeded / Failed / Skipped / Total] 1 / 2 / 6 / 9:  90%|█████████ | 9/10 [01:28<00:09,  9.78s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 8 ---------------------------------------------\n",
      "[[0 (54%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "Mind-bending and visually stunning! Inception keeps you guessing from start to finish. Christopher Nolan at his best.\n",
      "\n",
      "\n",
      "--------------------------------------------- Result 9 ---------------------------------------------\n",
      "[[0 (55%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "The Dark Knight is a dark and gripping superhero film. Heath Ledger's Joker is iconic. A must-see.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Succeeded / Failed / Skipped / Total] 1 / 2 / 6 / 9: 100%|██████████| 10/10 [01:28<00:00,  8.82s/it]\u001b[A\n",
      "[Succeeded / Failed / Skipped / Total] 1 / 2 / 7 / 10: 100%|██████████| 10/10 [01:28<00:00,  8.82s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 10 ---------------------------------------------\n",
      "[[0 (55%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "This film is a masterpiece! The story is incredibly moving, and the performances are outstanding. It's a true classic.\n",
      "\n",
      "\n",
      "\n",
      "+-------------------------------+--------+\n",
      "| Attack Results                |        |\n",
      "+-------------------------------+--------+\n",
      "| Number of successful attacks: | 1      |\n",
      "| Number of failed attacks:     | 2      |\n",
      "| Number of skipped attacks:    | 7      |\n",
      "| Original accuracy:            | 30.0%  |\n",
      "| Accuracy under attack:        | 20.0%  |\n",
      "| Attack success rate:          | 33.33% |\n",
      "| Average perturbed word %:     | 40.91% |\n",
      "| Average num. words per input: | 17.3   |\n",
      "| Avg num queries:              | 213.33 |\n",
      "+-------------------------------+--------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f0b2f2e9990>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f0bc2e74f70>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f0b0dbea8c0>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f0b09b3fc70>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f0b2f2e8bb0>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f0b09b3cac0>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f0b1bc46710>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f0b1bc44cd0>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f0b1bc46530>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f0b256fc580>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torch import nn\n",
    "import torch\n",
    "import math\n",
    "import textattack\n",
    "import random\n",
    "#from train_bert import Model\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "#torch.cuda.is_available = lambda : False\n",
    "textattack.shared.utils.device = \"cpu\"\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "        #self.bert_model.parallelize()\n",
    "        self.drop = torch.nn.Dropout(p=0.1)\n",
    "        self.l1 = torch.nn.Linear(768,2)\n",
    "\n",
    "    def forward(self, text):\n",
    "        tokenized_text = tokenizer(text , max_length=512, truncation=True, return_tensors='pt').input_ids#.to('cuda:3')\n",
    "        text_rep = self.drop(self.bert_model(tokenized_text).pooler_output)\n",
    "        out = self.l1(text_rep)\n",
    "        #print(out)\n",
    "\n",
    "        return out.squeeze().tolist()\n",
    "\n",
    "\n",
    "model = Model()\n",
    "#model.load_state_dict(torch.load('bert-base-uncased'))\n",
    "model = model.to('cpu')\n",
    "model.eval()\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "\n",
    "class CustomWrapper(textattack.models.wrappers.ModelWrapper):\n",
    "    def __init__(self, model):\n",
    "        self.model = model#.to('cuda:3')\n",
    "        self.model.eval()\n",
    "\n",
    "    def __call__(self, list_of_texts):\n",
    "        results = []\n",
    "        self.model.requires_grad = False\n",
    "        for text in list_of_texts:\n",
    "          \n",
    "          results.append(self.model(text))\n",
    "\n",
    "        return results\n",
    "\n",
    "\n",
    "class_model = CustomWrapper(model)\n",
    "\n",
    "\n",
    "from textattack.datasets import Dataset\n",
    "from textattack.attack_recipes.textfooler_jin_2019 import TextFoolerJin2019\n",
    "from textattack import Attacker, AttackArgs\n",
    "\n",
    "\n",
    "attack = TextFoolerJin2019.build(class_model)\n",
    "attack#.cuda_()\n",
    "        \n",
    "dataset = [\n",
    "    [\"This film is a masterpiece! The story is incredibly moving, and the performances are outstanding. It's a true classic.\", 1],\n",
    "    [\"The Godfather is a cinematic gem. The storytelling and performances are top-notch. A true classic in every sense.\", 1],\n",
    "    [\"The Emoji Movie is a complete disappointment. The plot is weak, and it feels like one big advertisement. A waste of time.\", 0],\n",
    "    [\"Mind-bending and visually stunning! Inception keeps you guessing from start to finish. Christopher Nolan at his best.\", 1],\n",
    "    [\"Twilight is a guilty pleasure for some, but the acting and dialogue are cringe-worthy. Not a cinematic masterpiece.\", 0],\n",
    "    [\"Forrest Gump is a heartwarming journey through history. Tom Hanks delivers an unforgettable performance.\", 1],\n",
    "    [\"Explosions and CGI can't make up for the lackluster story in Transformers: The Last Knight. Disappointing.\", 0],\n",
    "    [\"The Dark Knight is a dark and gripping superhero film. Heath Ledger's Joker is iconic. A must-see.\", 1],\n",
    "    [\"Avatar is visually breathtaking, but the story is somewhat predictable. Still, it's a cinematic experience.\", 1],\n",
    "    [\"The Room is so bad that it's almost good. The unintentional humor makes it a cult classic.\", 1]\n",
    "]\n",
    "\n",
    "random.shuffle(dataset)\n",
    "\n",
    "attacker = Attacker(attack, textattack.datasets.Dataset(dataset[:10]), AttackArgs(num_examples=10))\n",
    "attacker.attack_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-20T06:50:11.382049Z",
     "iopub.status.busy": "2023-09-20T06:50:11.381080Z",
     "iopub.status.idle": "2023-09-20T06:55:48.495560Z",
     "shell.execute_reply": "2023-09-20T06:55:48.494621Z",
     "shell.execute_reply.started": "2023-09-20T06:50:11.382007Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Unknown if model of class <class '__main__.ClassificationModel'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack(\n",
      "  (search_method): GreedyWordSwapWIR(\n",
      "    (wir_method):  delete\n",
      "  )\n",
      "  (goal_function):  UntargetedClassification\n",
      "  (transformation):  WordSwapEmbedding(\n",
      "    (max_candidates):  50\n",
      "    (embedding):  WordEmbedding\n",
      "  )\n",
      "  (constraints): \n",
      "    (0): WordEmbeddingDistance(\n",
      "        (embedding):  WordEmbedding\n",
      "        (min_cos_sim):  0.5\n",
      "        (cased):  False\n",
      "        (include_unknown_words):  True\n",
      "        (compare_against_original):  True\n",
      "      )\n",
      "    (1): PartOfSpeech(\n",
      "        (tagger_type):  nltk\n",
      "        (tagset):  universal\n",
      "        (allow_verb_noun_swap):  True\n",
      "        (compare_against_original):  True\n",
      "      )\n",
      "    (2): UniversalSentenceEncoder(\n",
      "        (metric):  angular\n",
      "        (threshold):  0.840845057\n",
      "        (window_size):  15\n",
      "        (skip_text_shorter_than_window):  True\n",
      "        (compare_against_original):  False\n",
      "      )\n",
      "    (3): RepeatModification\n",
      "    (4): StopwordModification\n",
      "    (5): InputColumnModification(\n",
      "        (matching_column_labels):  ['premise', 'hypothesis']\n",
      "        (columns_to_ignore):  {'premise'}\n",
      "      )\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 10%|█         | 1/10 [02:00<18:05, 120.61s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 1 / 0 / 1:  10%|█         | 1/10 [02:00<18:05, 120.62s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 1 ---------------------------------------------\n",
      "[[0 (50%)]] --> [[[FAILED]]]\n",
      "\n",
      "Explosions and CGI can't make up for the lackluster story in Transformers: The Last Knight. Disappointing.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 1 / 0 / 1:  20%|██        | 2/10 [02:01<08:04, 60.51s/it] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 1 / 1 / 2:  20%|██        | 2/10 [02:01<08:04, 60.51s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 2 ---------------------------------------------\n",
      "[[0 (50%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "Forrest Gump is a heartwarming journey through history. Tom Hanks delivers an unforgettable performance.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 1 / 1 / 2:  30%|███       | 3/10 [02:01<04:43, 40.48s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 1 / 2 / 3:  30%|███       | 3/10 [02:01<04:43, 40.48s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 3 ---------------------------------------------\n",
      "[[0 (50%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "The Room is so bad that it's almost good. The unintentional humor makes it a cult classic.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 1 / 2 / 3:  40%|████      | 4/10 [02:55<04:23, 43.99s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 2 / 2 / 4:  40%|████      | 4/10 [02:55<04:23, 43.99s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 4 ---------------------------------------------\n",
      "[[0 (50%)]] --> [[[FAILED]]]\n",
      "\n",
      "Twilight is a guilty pleasure for some, but the acting and dialogue are cringe-worthy. Not a cinematic masterpiece.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 2 / 2 / 4:  50%|█████     | 5/10 [02:56<02:56, 35.27s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 2 / 3 / 5:  50%|█████     | 5/10 [02:56<02:56, 35.27s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 5 ---------------------------------------------\n",
      "[[0 (50%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "The Godfather is a cinematic gem. The storytelling and performances are top-notch. A true classic in every sense.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 2 / 3 / 5:  60%|██████    | 6/10 [05:32<03:41, 55.44s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 3 / 3 / 6:  60%|██████    | 6/10 [05:32<03:41, 55.44s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 6 ---------------------------------------------\n",
      "[[0 (50%)]] --> [[[FAILED]]]\n",
      "\n",
      "The Emoji Movie is a complete disappointment. The plot is weak, and it feels like one big advertisement. A waste of time.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 3 / 3 / 6:  70%|███████   | 7/10 [05:33<02:22, 47.58s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 3 / 4 / 7:  70%|███████   | 7/10 [05:33<02:22, 47.58s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 7 ---------------------------------------------\n",
      "[[0 (50%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "Avatar is visually breathtaking, but the story is somewhat predictable. Still, it's a cinematic experience.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 3 / 4 / 7:  80%|████████  | 8/10 [05:33<01:23, 41.69s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 3 / 5 / 8:  80%|████████  | 8/10 [05:33<01:23, 41.69s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 8 ---------------------------------------------\n",
      "[[0 (50%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "Mind-bending and visually stunning! Inception keeps you guessing from start to finish. Christopher Nolan at his best.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 3 / 5 / 8:  90%|█████████ | 9/10 [05:33<00:37, 37.10s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 3 / 6 / 9:  90%|█████████ | 9/10 [05:33<00:37, 37.10s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 9 ---------------------------------------------\n",
      "[[0 (50%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "The Dark Knight is a dark and gripping superhero film. Heath Ledger's Joker is iconic. A must-see.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 3 / 6 / 9: 100%|██████████| 10/10 [05:34<00:00, 33.44s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 3 / 7 / 10: 100%|██████████| 10/10 [05:34<00:00, 33.44s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 10 ---------------------------------------------\n",
      "[[0 (50%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "This film is a masterpiece! The story is incredibly moving, and the performances are outstanding. It's a true classic.\n",
      "\n",
      "\n",
      "\n",
      "+-------------------------------+-------+\n",
      "| Attack Results                |       |\n",
      "+-------------------------------+-------+\n",
      "| Number of successful attacks: | 0     |\n",
      "| Number of failed attacks:     | 3     |\n",
      "| Number of skipped attacks:    | 7     |\n",
      "| Original accuracy:            | 30.0% |\n",
      "| Accuracy under attack:        | 30.0% |\n",
      "| Attack success rate:          | 0.0%  |\n",
      "| Average perturbed word %:     | nan%  |\n",
      "| Average num. words per input: | 17.3  |\n",
      "| Avg num queries:              | 250.0 |\n",
      "+-------------------------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/opt/conda/lib/python3.10/site-packages/textattack/metrics/attack_metrics/words_perturbed.py:83: RuntimeWarning: Mean of empty slice.\n",
      "  average_perc_words_perturbed = self.perturbed_word_percentages.mean()\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f0bc43d88e0>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f0ab61e0520>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f0ab59870a0>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f0ab4358c70>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f0ab31f6a70>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f0ab2f3bfd0>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f0ab5986f50>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f0ab61e1060>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f0ab5953730>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f0ab2e1c130>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from torch import nn\n",
    "import torch\n",
    "import math\n",
    "import textattack\n",
    "import random\n",
    "\n",
    "\n",
    "#torch.cuda.is_available = lambda : False\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "torch.cuda.is_available = lambda : False\n",
    "textattack.shared.utils.device = \"cuda:0\"\n",
    "\n",
    "class ClassificationModel(nn.Module):\n",
    "    def __init__(self, model, pos_prompt, neg_prompt):\n",
    "        super(ClassificationModel, self).__init__()\n",
    "        self.tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "        self.model = GPT2LMHeadModel.from_pretrained(model)\n",
    "        #self.model.to('cuda:0')\n",
    "        self.model.eval()\n",
    "        self.pos_prompt = pos_prompt\n",
    "        self.neg_prompt = neg_prompt\n",
    "\n",
    "    def score(self, prompt, sentence, model):\n",
    "        tokenized_prompt = self.tokenizer.encode(prompt , max_length=1024, truncation=True, return_tensors='pt').to('cpu')\n",
    "        tokenized_all = self.tokenizer.encode(prompt + ' ' + sentence, max_length=1024, truncation=True, return_tensors='pt').to('cpu')\n",
    "\n",
    "        loss1=model(tokenized_all, labels=tokenized_all).loss \n",
    "        loss2 = model(tokenized_prompt, labels=tokenized_prompt).loss*len(tokenized_prompt[0])/len(tokenized_all[0])\n",
    "        loss = loss1-loss2\n",
    "        return math.exp(loss)\n",
    "    \n",
    "\n",
    "    def forward(self, sentence):\n",
    "        pos = 0\n",
    "        neg = 0\n",
    "        for prompt in self.pos_prompt:\n",
    "             pos += self.score(prompt, sentence, self.model)#.cpu()\n",
    "        for prompt in self.neg_prompt:\n",
    "             neg += self.score(prompt, sentence, self.model)#.cpu()\n",
    "        #print(neg)\n",
    "        result = torch.FloatTensor([5000-neg/10.0e+52, 5000-pos/10.0e+52])\n",
    "        #print('res', result)\n",
    "        result = torch.softmax(result, 0)\n",
    "        #print(pos)\n",
    "        #print(neg)\n",
    "        #print('result', result)\n",
    "        if abs(result[0].item()+result[1].item()-1) >= 1e-6:\n",
    "            print('detected something')\n",
    "            result = torch.FloatTensor([1,0])\n",
    "        return torch.softmax(result, 0)\n",
    "\n",
    "\n",
    "class TorchTokenizer(GPT2Tokenizer):\n",
    "    def __init__(self):\n",
    "        super(TorchTokenizer, self).__init__()\n",
    "\n",
    "\n",
    "class CustomWrapper(textattack.models.wrappers.ModelWrapper):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def __call__(self, list_of_texts):\n",
    "        results = []\n",
    "        for text in list_of_texts:\n",
    "          results.append(self.model(text))\n",
    "\n",
    "        return torch.stack(results)\n",
    "\n",
    "\n",
    "\n",
    "#model = ClassificationModel('gpt2-xl', ['I loved this movie!','A great film!', \"This was an awesome movie!\", \"This movie was extremely good!\", \"This was the best movie I have ever seen!\", \"I found the movie to be very good.\", \"This film was fantastic!\"], ['I hated this movie!', 'A bad film!', \"This was a terrible movie!\", \"This movie was really bad!\", \"This was the worst movie I have ever seen!\", \"I found the movie to be very bad.\", \"This film was boring.\"]).to('cuda:2')\n",
    "model = ClassificationModel('gpt2', ['Positive:'], ['Negative:'])\n",
    "class_model = CustomWrapper(model)\n",
    "\n",
    "\n",
    "from textattack.datasets import Dataset\n",
    "from textattack.attack_recipes.textfooler_jin_2019 import TextFoolerJin2019\n",
    "from textattack import Attacker, AttackArgs\n",
    "\n",
    "class_model =CustomWrapper(model)\n",
    "attack = TextFoolerJin2019.build(class_model)\n",
    "\n",
    "dataset = [\n",
    "    [\"This film is a masterpiece! The story is incredibly moving, and the performances are outstanding. It's a true classic.\", 1],\n",
    "    [\"The Godfather is a cinematic gem. The storytelling and performances are top-notch. A true classic in every sense.\", 1],\n",
    "    [\"The Emoji Movie is a complete disappointment. The plot is weak, and it feels like one big advertisement. A waste of time.\", 0],\n",
    "    [\"Mind-bending and visually stunning! Inception keeps you guessing from start to finish. Christopher Nolan at his best.\", 1],\n",
    "    [\"Twilight is a guilty pleasure for some, but the acting and dialogue are cringe-worthy. Not a cinematic masterpiece.\", 0],\n",
    "    [\"Forrest Gump is a heartwarming journey through history. Tom Hanks delivers an unforgettable performance.\", 1],\n",
    "    [\"Explosions and CGI can't make up for the lackluster story in Transformers: The Last Knight. Disappointing.\", 0],\n",
    "    [\"The Dark Knight is a dark and gripping superhero film. Heath Ledger's Joker is iconic. A must-see.\", 1],\n",
    "    [\"Avatar is visually breathtaking, but the story is somewhat predictable. Still, it's a cinematic experience.\", 1],\n",
    "    [\"The Room is so bad that it's almost good. The unintentional humor makes it a cult classic.\", 1]\n",
    "]\n",
    "random.shuffle(dataset)\n",
    "\n",
    "attacker = Attacker(attack, textattack.datasets.Dataset(dataset[:10]), AttackArgs(num_examples=10))\n",
    "attacker.attack_dataset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
